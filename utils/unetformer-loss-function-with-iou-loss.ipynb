{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb57d5ac",
   "metadata": {
    "papermill": {
     "duration": 0.006451,
     "end_time": "2023-12-05T12:40:20.725634",
     "exception": false,
     "start_time": "2023-12-05T12:40:20.719183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://github.com/WangLibo1995/GeoSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcf5a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:20.742262Z",
     "iopub.status.busy": "2023-12-05T12:40:20.741850Z",
     "iopub.status.idle": "2023-12-05T12:40:44.262252Z",
     "shell.execute_reply": "2023-12-05T12:40:44.260856Z"
    },
    "papermill": {
     "duration": 23.531527,
     "end_time": "2023-12-05T12:40:44.265286",
     "exception": false,
     "start_time": "2023-12-05T12:40:20.733759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models_pytorch\r\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.15.1+cpu)\r\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting timm==0.9.2 (from segmentation_models_pytorch)\r\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0+cpu)\r\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.16.4)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.3.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.7.22)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=bdb83e9c0297955f02ceba84455f7c91b150b534dd8dc2c7a870b35649d85d81\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=da19a9b0a5edb1f340ca8655e90f06d5a8fa21fee3a0cf98322e8da2dfddad2d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.7\r\n",
      "    Uninstalling timm-0.9.7:\r\n",
      "      Successfully uninstalled timm-0.9.7\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6638ccb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:44.285676Z",
     "iopub.status.busy": "2023-12-05T12:40:44.284924Z",
     "iopub.status.idle": "2023-12-05T12:40:51.902416Z",
     "shell.execute_reply": "2023-12-05T12:40:51.901369Z"
    },
    "papermill": {
     "duration": 7.630752,
     "end_time": "2023-12-05T12:40:51.905154",
     "exception": false,
     "start_time": "2023-12-05T12:40:44.274402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import numpy as np\n",
    "from torch import nn, Tensor\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b92325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:51.925862Z",
     "iopub.status.busy": "2023-12-05T12:40:51.925142Z",
     "iopub.status.idle": "2023-12-05T12:40:51.933522Z",
     "shell.execute_reply": "2023-12-05T12:40:51.932739Z"
    },
    "papermill": {
     "duration": 0.021412,
     "end_time": "2023-12-05T12:40:51.935903",
     "exception": false,
     "start_time": "2023-12-05T12:40:51.914491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_dice_score(\n",
    "    output: torch.Tensor, target: torch.Tensor, smooth: float = 0.0, eps: float = 1e-7, dims=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    :param output:\n",
    "    :param target:\n",
    "    :param smooth:\n",
    "    :param eps:\n",
    "    :return:\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, NC, *)` where :math:`*` means any number\n",
    "            of additional dimensions\n",
    "        - Target: :math:`(N, NC, *)`, same shape as the input\n",
    "        - Output: scalar.\n",
    "\n",
    "    \"\"\"\n",
    "    assert output.size() == target.size()\n",
    "    if dims is not None:\n",
    "        intersection = torch.sum(output * target, dim=dims)\n",
    "        cardinality = torch.sum(output + target, dim=dims)\n",
    "    else:\n",
    "        intersection = torch.sum(output * target)\n",
    "        cardinality = torch.sum(output + target)\n",
    "    dice_score = (2.0 * intersection + smooth) / (cardinality + smooth).clamp_min(eps)\n",
    "    return dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b70136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:51.955759Z",
     "iopub.status.busy": "2023-12-05T12:40:51.954986Z",
     "iopub.status.idle": "2023-12-05T12:40:51.982582Z",
     "shell.execute_reply": "2023-12-05T12:40:51.981256Z"
    },
    "papermill": {
     "duration": 0.040822,
     "end_time": "2023-12-05T12:40:51.985455",
     "exception": false,
     "start_time": "2023-12-05T12:40:51.944633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BINARY_MODE = \"binary\"\n",
    "MULTICLASS_MODE = \"multiclass\"\n",
    "MULTILABEL_MODE = \"multilabel\"\n",
    "\n",
    "\n",
    "def to_tensor(x, dtype=None) -> torch.Tensor:\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        if dtype is not None:\n",
    "            x = x.type(dtype)\n",
    "        return x\n",
    "    if isinstance(x, np.ndarray) and x.dtype.kind not in {\"O\", \"M\", \"U\", \"S\"}:\n",
    "        x = torch.from_numpy(x)\n",
    "        if dtype is not None:\n",
    "            x = x.type(dtype)\n",
    "        return x\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        x = np.ndarray(x)\n",
    "        x = torch.from_numpy(x)\n",
    "        if dtype is not None:\n",
    "            x = x.type(dtype)\n",
    "        return x\n",
    "\n",
    "    raise ValueError(\"Unsupported input type\" + str(type(x)))\n",
    "\n",
    "\n",
    "class DiceLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Implementation of Dice loss for image segmentation task.\n",
    "    It supports binary, multiclass and multilabel cases\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'multiclass',\n",
    "        classes: List[int] = None,\n",
    "        log_loss=False,\n",
    "        from_logits=True,\n",
    "        smooth: float = 0.0,\n",
    "        ignore_index=None,\n",
    "        eps=1e-7,\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param mode: Metric mode {'binary', 'multiclass', 'multilabel'}\n",
    "        :param classes: Optional list of classes that contribute in loss computation;\n",
    "        By default, all channels are included.\n",
    "        :param log_loss: If True, loss computed as `-log(jaccard)`; otherwise `1 - jaccard`\n",
    "        :param from_logits: If True assumes input is raw logits\n",
    "        :param smooth:\n",
    "        :param ignore_index: Label that indicates ignored pixels (does not contribute to loss)\n",
    "        :param eps: Small epsilon for numerical stability\n",
    "        \"\"\"\n",
    "        assert mode in {BINARY_MODE, MULTILABEL_MODE, MULTICLASS_MODE}\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.mode = mode\n",
    "        if classes is not None:\n",
    "            assert mode != BINARY_MODE, \"Masking classes is not supported with mode=binary\"\n",
    "            classes = to_tensor(classes, dtype=torch.long)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.from_logits = from_logits\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "        self.ignore_index = ignore_index\n",
    "        self.log_loss = log_loss\n",
    "\n",
    "    def forward(self, y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        :param y_pred: NxCxHxW\n",
    "        :param y_true: NxHxW\n",
    "        :return: scalar\n",
    "        \"\"\"\n",
    "        assert y_true.size(0) == y_pred.size(0)\n",
    "\n",
    "        if self.from_logits:\n",
    "            # Apply activations to get [0..1] class probabilities\n",
    "            # Using Log-Exp as this gives more numerically stable result and does not cause vanishing gradient on\n",
    "            # extreme values 0 and 1\n",
    "            if self.mode == MULTICLASS_MODE:\n",
    "                y_pred = y_pred.log_softmax(dim=1).exp()\n",
    "            else:\n",
    "                y_pred = F.logsigmoid(y_pred).exp()\n",
    "\n",
    "        bs = y_true.size(0)\n",
    "        num_classes = y_pred.size(1)\n",
    "        dims = (0, 2)\n",
    "\n",
    "        if self.mode == BINARY_MODE:\n",
    "            y_true = y_true.view(bs, 1, -1)\n",
    "            y_pred = y_pred.view(bs, 1, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "\n",
    "        if self.mode == MULTICLASS_MODE:\n",
    "            y_true = y_true.view(bs, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask.unsqueeze(1)\n",
    "\n",
    "                y_true = F.one_hot((y_true * mask).to(torch.long), num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1) * mask.unsqueeze(1)  # H, C, H*W\n",
    "            else:\n",
    "                y_true = F.one_hot(y_true, num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1)  # H, C, H*W\n",
    "\n",
    "        if self.mode == MULTILABEL_MODE:\n",
    "            y_true = y_true.view(bs, num_classes, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "\n",
    "        scores = soft_dice_score(y_pred, y_true.type_as(y_pred), smooth=self.smooth, eps=self.eps, dims=dims)\n",
    "\n",
    "        if self.log_loss:\n",
    "            loss = -torch.log(scores.clamp_min(self.eps))\n",
    "        else:\n",
    "            loss = 1.0 - scores\n",
    "\n",
    "        # Dice loss is undefined for non-empty classes\n",
    "        # So we zero contribution of channel that does not have true pixels\n",
    "        # NOTE: A better workaround would be to use loss term `mean(y_pred)`\n",
    "        # for this case, however it will be a modified jaccard loss\n",
    "\n",
    "        mask = y_true.sum(dims) > 0\n",
    "        loss *= mask.to(loss.dtype)\n",
    "\n",
    "        if self.classes is not None:\n",
    "            loss = loss[self.classes]\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd610f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.005087Z",
     "iopub.status.busy": "2023-12-05T12:40:52.004645Z",
     "iopub.status.idle": "2023-12-05T12:40:52.013098Z",
     "shell.execute_reply": "2023-12-05T12:40:52.011882Z"
    },
    "papermill": {
     "duration": 0.021121,
     "end_time": "2023-12-05T12:40:52.015441",
     "exception": false,
     "start_time": "2023-12-05T12:40:51.994320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for nn.CrossEntropyLoss with few additions:\n",
    "    - Support of label smoothing\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction: str = \"mean\", smooth_factor: float = 0.0, ignore_index: Optional[int] = -100, dim=1):\n",
    "        super().__init__()\n",
    "        self.smooth_factor = smooth_factor\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        log_prob = F.log_softmax(input, dim=self.dim)\n",
    "        return label_smoothed_nll_loss(\n",
    "            log_prob,\n",
    "            target,\n",
    "            epsilon=self.smooth_factor,\n",
    "            ignore_index=self.ignore_index,\n",
    "            reduction=self.reduction,\n",
    "            dim=self.dim,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731e4ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.035687Z",
     "iopub.status.busy": "2023-12-05T12:40:52.034630Z",
     "iopub.status.idle": "2023-12-05T12:40:52.046226Z",
     "shell.execute_reply": "2023-12-05T12:40:52.045223Z"
    },
    "papermill": {
     "duration": 0.024258,
     "end_time": "2023-12-05T12:40:52.048815",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.024557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_smoothed_nll_loss(\n",
    "    lprobs: torch.Tensor, target: torch.Tensor, epsilon: float, ignore_index=None, reduction=\"mean\", dim=-1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Source: https://github.com/pytorch/fairseq/blob/master/fairseq/criterions/label_smoothed_cross_entropy.py\n",
    "\n",
    "    :param lprobs: Log-probabilities of predictions (e.g after log_softmax)\n",
    "    :param target:\n",
    "    :param epsilon:\n",
    "    :param ignore_index:\n",
    "    :param reduction:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if target.dim() == lprobs.dim() - 1:\n",
    "        target = target.unsqueeze(dim)\n",
    "\n",
    "    if ignore_index is not None:\n",
    "        pad_mask = target.eq(ignore_index)\n",
    "        target = target.masked_fill(pad_mask, 0)\n",
    "        nll_loss = -lprobs.gather(dim=dim, index=target)\n",
    "        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n",
    "\n",
    "        # nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "        # smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        nll_loss = nll_loss.masked_fill(pad_mask, 0.0)\n",
    "        smooth_loss = smooth_loss.masked_fill(pad_mask, 0.0)\n",
    "    else:\n",
    "        nll_loss = -lprobs.gather(dim=dim, index=target)\n",
    "        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n",
    "\n",
    "        nll_loss = nll_loss.squeeze(dim)\n",
    "        smooth_loss = smooth_loss.squeeze(dim)\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        nll_loss = nll_loss.sum()\n",
    "        smooth_loss = smooth_loss.sum()\n",
    "    if reduction == \"mean\":\n",
    "        nll_loss = nll_loss.mean()\n",
    "        smooth_loss = smooth_loss.mean()\n",
    "\n",
    "    eps_i = epsilon / lprobs.size(dim)\n",
    "    loss = (1.0 - epsilon) * nll_loss + eps_i * smooth_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f909c726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.068753Z",
     "iopub.status.busy": "2023-12-05T12:40:52.067671Z",
     "iopub.status.idle": "2023-12-05T12:40:52.076023Z",
     "shell.execute_reply": "2023-12-05T12:40:52.074569Z"
    },
    "papermill": {
     "duration": 0.021389,
     "end_time": "2023-12-05T12:40:52.078890",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.057501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_jaccard_score(\n",
    "    output: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    smooth: float = 0.0,\n",
    "    eps: float = 1e-7,\n",
    "    dims=None,\n",
    ") -> torch.Tensor:\n",
    "    assert output.size() == target.size()\n",
    "    if dims is not None:\n",
    "        intersection = torch.sum(output * target, dim=dims)\n",
    "        cardinality = torch.sum(output + target, dim=dims)\n",
    "    else:\n",
    "        intersection = torch.sum(output * target)\n",
    "        cardinality = torch.sum(output + target)\n",
    "\n",
    "    union = cardinality - intersection\n",
    "    jaccard_score = (intersection + smooth) / (union + smooth).clamp_min(eps)\n",
    "    return jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad97749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.098728Z",
     "iopub.status.busy": "2023-12-05T12:40:52.098311Z",
     "iopub.status.idle": "2023-12-05T12:40:52.119623Z",
     "shell.execute_reply": "2023-12-05T12:40:52.118732Z"
    },
    "papermill": {
     "duration": 0.034566,
     "end_time": "2023-12-05T12:40:52.122339",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.087773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JaccardLoss(_Loss):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'multiclass',\n",
    "        classes: Optional[List[int]] = None,\n",
    "        log_loss: bool = False,\n",
    "        from_logits: bool = True,\n",
    "        smooth: float = 0.0,\n",
    "        ignore_index: Optional[int] = None,\n",
    "        eps: float = 1e-7,\n",
    "    ):\n",
    "        \"\"\"Jaccard loss for image segmentation task.\n",
    "        It supports binary, multiclass and multilabel cases\n",
    "\n",
    "        Args:\n",
    "            mode: Loss mode 'binary', 'multiclass' or 'multilabel'\n",
    "            classes:  List of classes that contribute in loss computation. By default, all channels are included.\n",
    "            log_loss: If True, loss computed as `- log(jaccard_coeff)`, otherwise `1 - jaccard_coeff`\n",
    "            from_logits: If True, assumes input is raw logits\n",
    "            smooth: Smoothness constant for dice coefficient\n",
    "            eps: A small epsilon for numerical stability to avoid zero division error\n",
    "                (denominator will be always greater or equal to eps)\n",
    "\n",
    "        Shape\n",
    "             - **y_pred** - torch.Tensor of shape (N, C, H, W)\n",
    "             - **y_true** - torch.Tensor of shape (N, H, W) or (N, C, H, W)\n",
    "\n",
    "        Reference\n",
    "            https://github.com/BloodAxe/pytorch-toolbelt\n",
    "        \"\"\"\n",
    "        assert mode in {BINARY_MODE, MULTILABEL_MODE, MULTICLASS_MODE}\n",
    "        super(JaccardLoss, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "        if classes is not None:\n",
    "            assert mode != BINARY_MODE, \"Masking classes is not supported with mode=binary\"\n",
    "            classes = to_tensor(classes, dtype=torch.long)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.from_logits = from_logits\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "        self.log_loss = log_loss\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        assert y_true.size(0) == y_pred.size(0)\n",
    "\n",
    "        if self.from_logits:\n",
    "            # Apply activations to get [0..1] class probabilities\n",
    "            # Using Log-Exp as this gives more numerically stable result and does not cause vanishing gradient on\n",
    "            # extreme values 0 and 1\n",
    "            if self.mode == MULTICLASS_MODE:\n",
    "                y_pred = y_pred.log_softmax(dim=1).exp()\n",
    "            else:\n",
    "                y_pred = F.logsigmoid(y_pred).exp()\n",
    "\n",
    "        bs = y_true.size(0)\n",
    "        num_classes = y_pred.size(1)\n",
    "        dims = (0, 2)\n",
    "\n",
    "\n",
    "        if self.mode == BINARY_MODE:\n",
    "            y_true = y_true.view(bs, 1, -1)\n",
    "            y_pred = y_pred.view(bs, 1, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "\n",
    "        if self.mode == MULTICLASS_MODE:\n",
    "            y_true = y_true.view(bs, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask.unsqueeze(1)\n",
    "\n",
    "                y_true = F.one_hot((y_true * mask).to(torch.long), num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1) * mask.unsqueeze(1)  # H, C, H*W\n",
    "            else:\n",
    "                y_true = F.one_hot(y_true, num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1)  # H, C, H*W\n",
    "\n",
    "        if self.mode == MULTILABEL_MODE:\n",
    "            y_true = y_true.view(bs, num_classes, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "                \n",
    "        scores = soft_jaccard_score(\n",
    "            y_pred,\n",
    "            y_true.type(y_pred.dtype),\n",
    "            smooth=self.smooth,\n",
    "            eps=self.eps,\n",
    "            dims=dims,\n",
    "        )\n",
    "\n",
    "        if self.log_loss:\n",
    "            loss = -torch.log(scores.clamp_min(self.eps))\n",
    "        else:\n",
    "            loss = 1.0 - scores\n",
    "\n",
    "        # IoU loss is defined for non-empty classes\n",
    "        # So we zero contribution of channel that does not have true pixels\n",
    "        # NOTE: A better workaround would be to use loss term `mean(y_pred)`\n",
    "        # for this case, however it will be a modified jaccard loss\n",
    "\n",
    "        mask = y_true.sum(dims) > 0\n",
    "        loss *= mask.float()\n",
    "\n",
    "        if self.classes is not None:\n",
    "            loss = loss[self.classes]\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77aa657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.142549Z",
     "iopub.status.busy": "2023-12-05T12:40:52.141736Z",
     "iopub.status.idle": "2023-12-05T12:40:52.150372Z",
     "shell.execute_reply": "2023-12-05T12:40:52.149282Z"
    },
    "papermill": {
     "duration": 0.021501,
     "end_time": "2023-12-05T12:40:52.152826",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.131325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedLoss(_Loss):\n",
    "    \"\"\"Wrapper class around loss function that applies weighted with fixed factor.\n",
    "    This class helps to balance multiple losses if they have different scales\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loss, weight=1.0):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.loss(*input) * self.weight\n",
    "\n",
    "\n",
    "class JointLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Wrap two loss functions into one. This class computes a weighted sum of two losses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, first: nn.Module, second: nn.Module, first_weight=1.0, second_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.first = WeightedLoss(first, first_weight)\n",
    "        self.second = WeightedLoss(second, second_weight)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.first(*input) + self.second(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b32c335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.172847Z",
     "iopub.status.busy": "2023-12-05T12:40:52.172208Z",
     "iopub.status.idle": "2023-12-05T12:40:52.179621Z",
     "shell.execute_reply": "2023-12-05T12:40:52.178830Z"
    },
    "papermill": {
     "duration": 0.020316,
     "end_time": "2023-12-05T12:40:52.182081",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.161765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index),\n",
    "                                   DiceLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22df3281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.202240Z",
     "iopub.status.busy": "2023-12-05T12:40:52.201632Z",
     "iopub.status.idle": "2023-12-05T12:40:52.209690Z",
     "shell.execute_reply": "2023-12-05T12:40:52.208561Z"
    },
    "papermill": {
     "duration": 0.021369,
     "end_time": "2023-12-05T12:40:52.212599",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.191230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerIouDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(JaccardLoss(smooth=0.05, ignore_index=ignore_index),\n",
    "                                   DiceLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = JaccardLoss(smooth=0.05, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa70602e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.232652Z",
     "iopub.status.busy": "2023-12-05T12:40:52.232206Z",
     "iopub.status.idle": "2023-12-05T12:40:52.241248Z",
     "shell.execute_reply": "2023-12-05T12:40:52.239973Z"
    },
    "papermill": {
     "duration": 0.02189,
     "end_time": "2023-12-05T12:40:52.243535",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.221645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerDiceIouLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(DiceLoss(smooth=0.05, ignore_index=ignore_index),\n",
    "                                   JaccardLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = DiceLoss(smooth=0.05, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb09139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.264404Z",
     "iopub.status.busy": "2023-12-05T12:40:52.263699Z",
     "iopub.status.idle": "2023-12-05T12:40:52.272346Z",
     "shell.execute_reply": "2023-12-05T12:40:52.271295Z"
    },
    "papermill": {
     "duration": 0.022836,
     "end_time": "2023-12-05T12:40:52.275549",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.252713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerCEIouLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index),\n",
    "                                   JaccardLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61bf81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.296130Z",
     "iopub.status.busy": "2023-12-05T12:40:52.295707Z",
     "iopub.status.idle": "2023-12-05T12:40:52.305187Z",
     "shell.execute_reply": "2023-12-05T12:40:52.303908Z"
    },
    "papermill": {
     "duration": 0.022701,
     "end_time": "2023-12-05T12:40:52.307542",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.284841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerFocalIouLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(smp.losses.FocalLoss(mode='multiclass',gamma=2.0, ignore_index=ignore_index),\n",
    "                                   JaccardLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = smp.losses.FocalLoss(mode='multiclass',gamma=2.0, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7789e65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:40:52.328189Z",
     "iopub.status.busy": "2023-12-05T12:40:52.327752Z",
     "iopub.status.idle": "2023-12-05T12:40:52.336686Z",
     "shell.execute_reply": "2023-12-05T12:40:52.335575Z"
    },
    "papermill": {
     "duration": 0.021786,
     "end_time": "2023-12-05T12:40:52.338920",
     "exception": false,
     "start_time": "2023-12-05T12:40:52.317134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetFormerFocalDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(smp.losses.FocalLoss(mode='multiclass',gamma=2.0, ignore_index=ignore_index),\n",
    "                                   DiceLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = smp.losses.FocalLoss(mode='multiclass',gamma=2.0, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.855525,
   "end_time": "2023-12-05T12:40:53.573796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-05T12:40:16.718271",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
